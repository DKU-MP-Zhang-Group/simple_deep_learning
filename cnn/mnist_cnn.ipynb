{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":81106,"status":"ok","timestamp":1684845018444,"user":{"displayName":"rogue zhang","userId":"16157995007141085053"},"user_tz":-480},"id":"I58FphOh-Iuy","outputId":"09c80927-1075-48a9-d045-562cc51c4895"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:01<00:00, 5047272.53it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 3196529.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:16<00:00, 100732.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n","\n","True\n","Epoch [1/5], Step [100/118], Loss: 2.2495\n","Epoch [2/5], Step [100/118], Loss: 2.0065\n","Epoch [3/5], Step [100/118], Loss: 0.8978\n","Epoch [4/5], Step [100/118], Loss: 0.4764\n","Epoch [5/5], Step [100/118], Loss: 0.3203\n","Finished Training\n","Accuracy of the network on the 10000 test images: 91.02 %\n"]}],"source":["import numpy as np\n","import torch \n","from torch import nn\n","from torchvision import datasets, transforms,utils\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","# 定义超参数\n","batch_size = 512 # 每个批次（batch）的样本数\n","\n","# 对输入的数据进行标准化处理\n","# transforms.ToTensor() 将图像数据转换为 PyTorch 中的张量（tensor）格式，并将像素值缩放到 0-1 的范围内。\n","# 这是因为神经网络需要的输入数据必须是张量格式，并且需要进行归一化处理，以提高模型的训练效果。\n","# transforms.Normalize(mean=[0.5],std=[0.5]) 将图像像素值进行标准化处理，使其均值为 0，标准差为 1。\n","# 输入数据进行标准化处理可以提高模型的鲁棒性和稳定性，减少模型训练过程中的梯度爆炸和消失问题。\n","transform = transforms.Compose([transforms.ToTensor(),\n","                 transforms.Normalize(mean=[0.5],std=[0.5])])\n","\n","# 加载MNIST数据集\n","train_dataset = datasets.MNIST(root='./data', \n","                train=True, \n","                transform=transform, \n","                download=True)\n","test_dataset = datasets.MNIST(root='./data', \n","                train=False, \n","                transform=transform, \n","                download=True)\n","                                    \n","# 创建数据加载器（用于将数据分次放进模型进行训练）\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                      batch_size=batch_size, \n","                      shuffle=True, # 装载过程中随机乱序\n","                      num_workers=2) # 表示2个子进程加载数据\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                      batch_size=batch_size, \n","                      shuffle=False,\n","                      num_workers=2) \n","\n","class CNN(nn.Module):\n","    # 定义网络结构\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        # 图片是灰度图片，只有一个通道\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, \n","                    kernel_size=5, stride=1, padding=2)\n","        self.relu1 = nn.ReLU()\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, \n","                    kernel_size=5, stride=1, padding=2)\n","        self.relu2 = nn.ReLU()\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.fc1 = nn.Linear(in_features=7*7*32, out_features=256)\n","        self.relu3 = nn.ReLU()\n","        self.fc2 = nn.Linear(in_features=256, out_features=10)\n","\t\n","    # 定义前向传播过程的计算函数\n","    def forward(self, x):\n","        # 第一层卷积、激活函数和池化\n","        x = self.conv1(x)\n","        x = self.relu1(x)\n","        x = self.pool1(x)\n","        # 第二层卷积、激活函数和池化\n","        x = self.conv2(x)\n","        x = self.relu2(x)\n","        x = self.pool2(x)\n","        # 将数据平展成一维\n","        x = x.view(-1, 7*7*32)\n","        # 第一层全连接层\n","        x = self.fc1(x)\n","        x = self.relu3(x)\n","        # 第二层全连接层\n","        x = self.fc2(x)\n","        return x\n","\n","import torch.optim as optim\n","\n","learning_rate = 0.001 # 学习率\n","net = CNN() # 实例化CNN模型\n","# 定义损失函数，计算模型的输出与目标标签之间的交叉熵损失\n","criterion = nn.CrossEntropyLoss()\n","# 训练过程通常采用反向传播来更新模型参数，这里使用的是SDG(随机梯度下降)优化器\n","# momentum 表示动量因子，可以加速优化过程并提高模型的泛化性能。\n","optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n","#也可以选择Adam优化方法\n","# optimizer = torch.optim.Adam(net.parameters(),lr=1e-2)\n","\n","\n","num_epochs = 5 # 定义迭代次数\n","\n","# 如果可用的话使用 GPU 进行训练，否则使用 CPU 进行训练。\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(torch.cuda.is_available())\n","\n","# 将神经网络模型 net 移动到指定的设备上。\n","net = net.to(device)\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images,labels) in enumerate(train_loader):\n","        images=images.to(device)\n","        labels=labels.to(device)\n","        optimizer.zero_grad() # 清空上一个batch的梯度信息\n","        # 将输入数据 inputs 喂入神经网络模型 net 中进行前向计算，得到模型的输出结果 outputs。\n","        outputs=net(images) \n","        # 使用交叉熵损失函数 criterion 计算模型输出 outputs 与标签数据 labels 之间的损失值 loss。\n","        loss=criterion(outputs,labels)\n","        # 使用反向传播算法计算模型参数的梯度信息，并使用优化器 optimizer 对模型参数进行更新。\n","        loss.backward()\n","         # 更新梯度\n","        optimizer.step()\n","        # 输出训练结果\n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","\n","print('Finished Training')\n","\n","# 模型保存\n","PATH = './mnist_net.pth'\n","torch.save(net.state_dict(), PATH)\n","\n","# 测试CNN模型\n","with torch.no_grad(): # 进行评测的时候网络不更新梯度\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images=images.to(device)\n","        labels=labels.to(device)\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNoojzjsB5uFXCGdcwljhtR","gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
